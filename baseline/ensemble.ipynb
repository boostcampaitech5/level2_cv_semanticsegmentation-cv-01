{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inner_files(path, extension):\n",
    "    files = {\n",
    "        os.path.relpath(os.path.join(root, fname), start=path)\n",
    "        for root, _, files in os.walk(path)\n",
    "        for fname in files\n",
    "        if os.path.splitext(fname)[1].lower() == f\".{extension}\"\n",
    "    }\n",
    "    return sorted(files)\n",
    "\n",
    "def encode_mask_to_rle(mask):\n",
    "    \"\"\"\n",
    "    mask: numpy array binary mask\n",
    "    1 - mask\n",
    "    0 - background\n",
    "    Returns encoded run length\n",
    "    \"\"\"\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return \" \".join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n",
    "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n",
    "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n",
    "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n",
    "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n",
    "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n",
    "]\n",
    "ind2class = {i: v for i, v in enumerate(CLASSES)}\n",
    "\n",
    "basepath = \"/opt/ml/level2_cv_semanticsegmentation-cv-01\"\n",
    "\n",
    "bh_basepath = os.path.join(basepath, \"bh\")\n",
    "dg_basepath = os.path.join(basepath, \"dg\")\n",
    "hj_basepath = os.path.join(basepath, \"hj\")\n",
    "\n",
    "filenames = get_inner_files(bh_basepath, 'npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(basepath, filename):\n",
    "    image_path = os.path.join(basepath, filename)\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m outputs\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39mload(dg_image_path)[\u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     12\u001b[0m \u001b[39m# outputs.append(torch.from_numpy(np.load(hj_image_path)['array']))\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[39m# outputs = torch.stack(outputs)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# outputs = torch.mean(outputs, dim=0)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[39m=\u001b[39m (outputs[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mweight[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m outputs[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mweight[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m outputs[\u001b[39m2\u001b[39;49m]\u001b[39m*\u001b[39mweight[\u001b[39m2\u001b[39m]) \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39msum(weight)\n\u001b[1;32m     17\u001b[0m output \u001b[39m=\u001b[39m (output \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m c, segm \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(output):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "rles = []\n",
    "filename_and_class = []\n",
    "weight = torch.tensor([2, 1.5, 0.7])\n",
    "for filename in filenames:\n",
    "    bh_image_path = get_image_path(bh_basepath, filename)\n",
    "    dg_image_path = get_image_path(dg_basepath, filename)\n",
    "    hj_image_path = get_image_path(hj_basepath, filename)\n",
    "\n",
    "    outputs = []\n",
    "    outputs.append(torch.from_numpy(np.load(bh_image_path)['array']))\n",
    "    outputs.append(torch.from_numpy(np.load(dg_image_path)['array']))\n",
    "    outputs.append(torch.from_numpy(np.load(hj_image_path)['array']))\n",
    "\n",
    "    # outputs = torch.stack(outputs)\n",
    "    # outputs = torch.mean(outputs, dim=0)\n",
    "    output = (outputs[0]*weight[0] + outputs[1]*weight[1] + outputs[2]*weight[2]) / torch.sum(weight)\n",
    "    output = (output > 0.5).detach().cpu().numpy()\n",
    "\n",
    "    for c, segm in enumerate(output):\n",
    "        rle = encode_mask_to_rle(segm)\n",
    "        rles.append(rle)\n",
    "        filename_and_class.append(f\"{ind2class[c]}_{filename.split('.')[0]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"/opt/ml/level2_cv_semanticsegmentation-cv-01/output\"\n",
    "classes, filename = zip(*[x.split(\"_\") for x in filename_and_class])\n",
    "image_name = [os.path.basename(f) for f in filename]\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"image_name\": image_name,\n",
    "        \"class\": classes,\n",
    "        \"rle\": rles,\n",
    "    }\n",
    ")\n",
    "df.to_csv(os.path.join(output_path, \"Strength_lies_in_unity.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_path = \"/opt/ml/level2_cv_semanticsegmentation-cv-01/output/hrnet_48w_ocr_1024_augSet_full.csv\"\n",
    "compare_path = \"/opt/ml/level2_cv_semanticsegmentation-cv-01/output/Strength_lies_in_unity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rle_to_mask(rle, height, width):\n",
    "    s = rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(height * width, dtype=np.uint8)\n",
    "    \n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    \n",
    "    return img.reshape(height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "origin_df = pd.read_csv(origin_path)\n",
    "origin_image_info = defaultdict(dict)\n",
    "origin_image_names = list(set(origin_df['image_name']))\n",
    "for image_name, class_name, rle in zip(origin_df['image_name'], origin_df['class'], origin_df['rle']):\n",
    "    origin_image_info[image_name][class_name] = rle\n",
    "\n",
    "compare_df = pd.read_csv(compare_path)\n",
    "compare_image_info = defaultdict(dict)\n",
    "compare_image_names = list(set(origin_df['image_name']))\n",
    "for image_name, class_name, rle in zip(compare_df['image_name'], compare_df['class'], compare_df['rle']):\n",
    "    compare_image_info[image_name][class_name] = rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7083)\n",
      "tensor(10164)\n",
      "tensor(7113)\n",
      "tensor(7487)\n",
      "tensor(7610)\n",
      "tensor(9445)\n",
      "tensor(7641)\n",
      "tensor(6236)\n",
      "tensor(8233)\n",
      "tensor(8111)\n",
      "tensor(9179)\n",
      "tensor(9487)\n",
      "tensor(12633)\n",
      "tensor(7468)\n",
      "tensor(11432)\n",
      "tensor(10386)\n",
      "tensor(8370)\n",
      "tensor(14483)\n",
      "tensor(9425)\n",
      "tensor(9120)\n",
      "tensor(9468)\n",
      "tensor(9742)\n",
      "tensor(11855)\n",
      "tensor(10724)\n",
      "tensor(7261)\n",
      "tensor(9547)\n",
      "tensor(9685)\n",
      "tensor(9268)\n",
      "tensor(9054)\n",
      "tensor(9844)\n",
      "tensor(7811)\n",
      "tensor(9228)\n",
      "tensor(8681)\n",
      "tensor(12250)\n",
      "tensor(7004)\n",
      "tensor(7556)\n",
      "tensor(8179)\n",
      "tensor(8839)\n",
      "tensor(9805)\n",
      "tensor(9377)\n",
      "tensor(9956)\n",
      "tensor(8746)\n",
      "tensor(11597)\n",
      "tensor(9552)\n",
      "tensor(6609)\n",
      "tensor(13543)\n",
      "tensor(8236)\n",
      "tensor(8921)\n",
      "tensor(8439)\n",
      "tensor(10290)\n",
      "tensor(12875)\n",
      "tensor(9539)\n",
      "tensor(8824)\n",
      "tensor(9067)\n",
      "tensor(9875)\n",
      "tensor(8064)\n",
      "tensor(8962)\n",
      "tensor(9286)\n",
      "tensor(9279)\n",
      "tensor(7811)\n",
      "tensor(13018)\n",
      "tensor(6010)\n",
      "tensor(10688)\n",
      "tensor(10207)\n",
      "tensor(8664)\n",
      "tensor(8668)\n",
      "tensor(11915)\n",
      "tensor(10009)\n",
      "tensor(10339)\n",
      "tensor(7609)\n",
      "tensor(6300)\n",
      "tensor(13308)\n",
      "tensor(7806)\n",
      "tensor(9019)\n",
      "tensor(9016)\n",
      "tensor(8206)\n",
      "tensor(5338)\n",
      "tensor(11071)\n",
      "tensor(9490)\n",
      "tensor(8276)\n",
      "tensor(8628)\n",
      "tensor(9476)\n",
      "tensor(8708)\n",
      "tensor(9931)\n",
      "tensor(9719)\n",
      "tensor(10043)\n",
      "tensor(11262)\n",
      "tensor(12934)\n",
      "tensor(7623)\n",
      "tensor(10675)\n",
      "tensor(7523)\n",
      "tensor(10820)\n",
      "tensor(10713)\n",
      "tensor(9880)\n",
      "tensor(10641)\n",
      "tensor(10755)\n",
      "tensor(7839)\n",
      "tensor(6259)\n",
      "tensor(9655)\n",
      "tensor(16277)\n",
      "tensor(8374)\n",
      "tensor(11208)\n",
      "tensor(8586)\n",
      "tensor(7445)\n",
      "tensor(8228)\n",
      "tensor(9085)\n",
      "tensor(9072)\n",
      "tensor(8792)\n",
      "tensor(7149)\n",
      "tensor(6994)\n",
      "tensor(9438)\n",
      "tensor(8162)\n",
      "tensor(9627)\n",
      "tensor(7860)\n",
      "tensor(6629)\n",
      "tensor(9526)\n",
      "tensor(10042)\n",
      "tensor(9491)\n",
      "tensor(8501)\n",
      "tensor(11411)\n",
      "tensor(9547)\n",
      "tensor(7775)\n",
      "tensor(7313)\n",
      "tensor(8140)\n",
      "tensor(11521)\n",
      "tensor(7758)\n",
      "tensor(10385)\n",
      "tensor(7618)\n",
      "tensor(8595)\n",
      "tensor(8502)\n",
      "tensor(8974)\n",
      "tensor(11454)\n",
      "tensor(15723)\n",
      "tensor(9817)\n",
      "tensor(6992)\n",
      "tensor(6697)\n",
      "tensor(9222)\n",
      "tensor(9243)\n",
      "tensor(9123)\n",
      "tensor(7198)\n",
      "tensor(6811)\n",
      "tensor(6761)\n",
      "tensor(10666)\n",
      "tensor(7979)\n",
      "tensor(9157)\n",
      "tensor(6001)\n",
      "tensor(10929)\n",
      "tensor(8758)\n"
     ]
    }
   ],
   "source": [
    "for image_name in origin_image_names:\n",
    "    origin_pred, compare_pred = [], []\n",
    "    for origin_rle, compare_rle  in zip(origin_image_info[image_name].values(), compare_image_info[image_name].values()):\n",
    "        origin_pred.append(decode_rle_to_mask(origin_rle, height=2048, width=2048))\n",
    "        compare_pred.append(decode_rle_to_mask(compare_rle, height=2048, width=2048))\n",
    "    origin_pred = torch.from_numpy(np.stack(origin_pred, 0))\n",
    "    compare_pred = torch.from_numpy(np.stack(compare_pred, 0))\n",
    "    print(torch.sum(origin_pred != compare_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
